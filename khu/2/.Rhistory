recipe(PersonalLoan ~ ., data = raw.train) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep()
raw.rec
# Data Recipe
#
# Inputs:
#
#       role #variables
#    outcome          1
#  predictor         13
#
# Training data contained 3500 data points and no missing data.
#
# Operations:
#
# Box-Cox transformation on ID, Age, Income [trained]
# Centering and scaling for ID, Age, Experience, Income, ... [trained]
# Correlation filter removed Age [trained]
# Centering for ID, Experience, Income, ZIPCode, ... [trained]
# Scaling for ID, Experience, Income, ZIPCode, ... [trained]
raw.rec %>% juice() -> rec.train # 훈련 데이터 처리
raw.rec %>% bake(raw.test) -> rec.test # 테스트 데이터 처리
parsnip::rand_forest(trees = 100, mode = "classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
raw.rf
# 결과 확인
raw.rf %>% predict(rec.test)
# 결과 확인
raw.rf %>% predict(rec.test) %>%
bind_cols(rec.test)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test) %>%
metrics(truth=PersonalLoan, estimate=.pred)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test) %>%
metrics(truth=PersonalLoan, estimate=.class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test) %>%
metrics(truth=PersonalLoan, estimate=.pred)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test)
rec.train
rec.train %>% select(PersonalLoan)
raw.rec
raw %>% select(PersonalLoan)
raw.rf %>%
predict(rec.test)
raw.rf %>%
predict(rec.test) %>%
bind_cols(rec.test) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
rec.test %>% select(PersonalLoan)
rec.test %>% select(PersonalLoan) -> truth
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
mutate(obs = PersonalLoan,
pred = .pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) -> conf.nat.data
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred)
raw.rec <-
recipe(PersonalLoan ~ ., data = raw.train) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep()
raw.rec
# Data Recipe
#
# Inputs:
#
#       role #variables
#    outcome          1
#  predictor         13
#
# Training data contained 3500 data points and no missing data.
#
# Operations:
#
# Box-Cox transformation on ID, Age, Income [trained]
# Centering and scaling for ID, Age, Experience, Income, ... [trained]
# Correlation filter removed Age [trained]
# Centering for ID, Experience, Income, ZIPCode, ... [trained]
# Scaling for ID, Experience, Income, ZIPCode, ... [trained]
raw.rec %>% juice() -> rec.train # 훈련 데이터 처리
raw.rec %>% bake(raw.test) -> rec.test # 테스트 데이터 처리
parsnip::rand_forest(trees = 100, mode = "classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
# 결과 확인
raw.rf %>% predict(rec.test) %>%
bind_cols(rec.test)
# # A tibble: 1,500 x 15
#    .pred_class    ID    Age Experience Income ZIPCode Family   CCAvg
#    <fct>       <dbl>  <dbl>      <dbl>  <dbl>   <dbl>  <dbl>   <dbl>
#  1 0           -1.73 -0.562     -0.454 -1.35   0.697  -1.22  -0.530
#  2 0           -1.73 -0.912     -0.977  0.592  0.427  -1.22   0.462
#  3 0           -1.73 -0.737     -0.629 -0.961 -0.456   1.40  -0.880
#  4 0           -1.73  0.399      0.331 -1.11   0.352  -1.22  -0.939
#  5 0           -1.73 -0.912     -0.890  0.176 -1.36    0.529 -0.764
#  6 0           -1.73  1.88       1.81   0.854 -0.625  -1.22   0.0531
#  7 0           -1.72 -1.44      -1.33  -0.239 -1.28   -1.22  -0.414
#  8 0           -1.72 -0.126     -0.193 -0.655 -0.812  -0.345 -0.705
#  9 0           -1.71  1.19       1.29  -0.829 -0.0192 -1.22  -0.414
# 10 0           -1.71  0.661      0.680 -0.698  0.733  -0.345 -0.764
# # … with 1,490 more rows, and 7 more variables: Education <dbl>,
# #   Mortgage <dbl>, SecuritiesAccount <dbl>, CDAccount <dbl>,
# #   Online <dbl>, CreditCard <dbl>, PersonalLoan <fct>
rec.test %>% select(PersonalLoan) -> truth
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
# # A tibble: 2 x 3
#   .metric  .estimator .estimate
#   <chr>    <chr>          <dbl>
# 1 accuracy binary         0.895
# 2 kap      binary         0
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred)
raw.rec %>% juice() -> rec.train # 훈련 데이터 처리
raw.rec %>% bake(raw.test) -> rec.test # 테스트 데이터 처리
parsnip::rand_forest(trees = 100, mode = "classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
raw.rf %>% predict(rec.test) %>%
bind_cols(rec.test)
rec.test %>% select(PersonalLoan) -> truth
# 결과 확인
raw.rf %>% predict(rec.test) %>%
bind_cols(truth)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
# 랜덤포레스트 with Tidymodels
raw.rec <-
recipe(PersonalLoan ~ ., data = raw.train) %>%
prep()
raw.rec
raw.rec %>% juice() -> rec.train # 훈련 데이터 처리
raw.rec %>% bake(raw.test) -> rec.test # 테스트 데이터 처리
parsnip::rand_forest(trees = 100, mode = "classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
rec.test %>% select(PersonalLoan) -> truth
# 결과 확인
raw.rf %>% predict(rec.test) %>%
bind_cols(truth)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred) %>%
ggplot2::autoplot(type = "heatmap")
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_auc()
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_auc(obs, pred)
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_curve(obs, pred)
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_curve(obs, pred) %>
two_class_example
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_curve(obs, 0)
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_curve(obs, "0")
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_curve(obs, "1")
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_curve(obs, Class1)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class)
two_class_example
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) -> data
roc_curve(data)
roc_curve(data, obs, pred)
roc_curve(data, obs, estimate = pred)
roc_curve(data, obs, estimate = .0)
roc_curve(data, obs, estimate = .pred_class)
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
roc_curve(data, PersonalLoan, estimate = .pred_class)
# ROC 커브
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
roc_curve(PersonalLoan, estimate = .pred_class)
# 시각화
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred) %>%
ggplot2::autoplot(type = "heatmap")
measure_importance(raw.rf$fit)
pacman::p_load(tidyverse, magrittr, # helper packages
tidymodels, rstatix, randomForest, randomForestExplainer,# modeling packages
ggpubr) #  visualization
randomForestExplainer::measure_importance(raw.rf$fit)
measure_importance(raw.rf$fit) %>%
as_tibble() %>%
mutate(imp=node_purity_increase*100/max(node_purity_increase)) %>%
arrange(-imp) %>%
select(variable, imp)
measure_importance(raw.rf$fit) %>%
as_tibble()
read_csv("UniversalBank.csv") -> raw
raw %>% glimpse()
raw %<>%
mutate(PersonalLoan = as.factor(PersonalLoan)) # 종속변수 팩터화
# 데이터 분할 ----------------------------------------------
set.seed(123)
raw.split <- rsample::initial_split(raw , strata = PersonalLoan,
prop = 0.70)
raw.train <- training(raw.split) # Analysis를 학습으로 적재
raw.test  <-  testing(raw.split) # Assess를 테스트로 적재
raw.train %>%  skimr::skim()
# 랜덤포레스트 with Tidymodels
parsnip::rand_forest(trees = 1000, min_n = tune()) %>%
set_mode("classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
# 결과 확인
raw.rf %>% predict(rec.test) %>%
bind_cols(truth)
rec.test %>% select(PersonalLoan) -> truth
raw.test %>% select(PersonalLoan) -> truth
# 결과 확인
raw.rf %>% predict(raw.test) %>%
bind_cols(truth)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
# 랜덤포레스트 with Tidymodels
parsnip::rand_forest(trees = 1000, min_n = tune()) %>%
set_mode("classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
raw.test %>% select(PersonalLoan) -> truth
# 결과 확인
raw.rf %>% predict(raw.test) %>%
bind_cols(truth)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred)
# 랜덤포레스트 with Tidymodels
parsnip::rand_forest(trees = 1000) %>%
set_mode("classification") %>%
set_engine("randomForest") %>%
fit(PersonalLoan ~ ., data = raw.train) -> raw.rf
raw.rf %>% predict(raw.test)
# 결과 확인
raw.rf %>% predict(raw.test) %>%
bind_cols(truth)
raw.test %>% select(PersonalLoan) -> truth
# 결과 확인
raw.rf %>% predict(raw.test) %>%
bind_cols(truth)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
metrics(truth=PersonalLoan, estimate=.pred_class)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred)
# 혼동행렬 시각화
raw.rf %>%
predict(rec.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred) %>%
ggplot2::autoplot(type = "heatmap")
# 혼동행렬 시각화
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(obs, pred) %>%
ggplot2::autoplot(type = "heatmap")
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(truth = obs, estimate = pred)
raw.rf %>%
predict(raw.test)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(truth = obs, estimate = pred)
roc_auc(truth = obs, 0)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_auc(obs, 0)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_auc(obs, 1)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
roc_auc(obs, 0)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = as.factor(PersonalLoan),
pred = as.factor(.pred_class))
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = as.factor(PersonalLoan),
pred = as.factor(.pred_class))
raw.rf %>%
predict(raw.test)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = factor(PersonalLoan),
pred = .pred_class) %>%
conf_mat(truth = obs, estimate = pred)
raw.rf
raw.rf %>%
predict(raw.test)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth)
conf_mat(truth = obs, estimate = pred)
raw.rf %>%
predict(raw.test) %>%
bind_cols(truth) %>%
rename(obs = PersonalLoan,
pred = .pred_class) %>%
conf_mat(truth = obs, estimate = pred)
two_class_example
# 랜덤포레스트 with Tidymodels
p = ncol(raw.train) - 1 # class 뺀 X변수들의 숫자
n = nrow(raw.train)
mtry = floor(seq(0.1, 1, by = 0.1) * p)
nsize = round(c(1, n * seq(0.01, 0.1, by = 0.01)))
pna = matrix(NA, nrow = length(mtry), ncol = length(nsize))
pnadf = data.frame()
for( i in 1:length(mtry)){
for( j in 1:length(nsize)){
m = mtry[i]
n = nsize[j]
rf = randomForest(target_class~.,
data = train, ntree = 100, mtry = m,
nodesize = n, set.seed(0226))
pred = predict(rf, newdata = test, type = 'prob')
roccurve0 = roc(test$target_class ~ pred[,2])
auc = roccurve0$auc %>% as.numeric()
pna[i,j] = auc
pnadf = rbind(pnadf, c(m,n,auc))
}
}
m
for( i in 1:length(mtry)){
for( j in 1:length(nsize)){
m = mtry[i]
n = nsize[j]
rf = randomForest(target_class~.,
data = train, ntree = 100, mtry = m,
nodesize = n, set.seed(0226))
pred = predict(rf, newdata = test, type = 'prob')
roccurve0 = roc(test$target_class ~ pred[,2])
auc = roccurve0$auc %>% as.numeric()
pna[i,j] = auc
pnadf = rbind(pnadf, c(m,n,auc))
}
}
